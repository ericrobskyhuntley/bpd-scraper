{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import d6tjoin.top1\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas and reverse last-first.\n",
    "bpd = pd.read_csv('./data/employee_earnings.csv')\n",
    "bpd.columns = map(str.lower, bpd.columns)\n",
    "bpd = bpd[bpd.department_name.eq('Boston Police Department')]\n",
    "bpd.loc[:,'name'] = bpd.name.str.split(pat = ',').apply(lambda x: ' '.join(x[::-1]))\n",
    "bpd.loc[:,'name'] = bpd.name.str.split(pat = r' [a-zA-Z]\\. ').apply(lambda x: ' '.join(x))\n",
    "bpd.loc[:,'name'] = bpd.name.str.split(pat = r' [a-zA-Z] ').apply(lambda x: ' '.join(x))\n",
    "bpd.loc[:,'postal'] = bpd.postal.astype(str).apply(lambda x: '0'+ x)\n",
    "bpd = bpd.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "bpd.replace(r'^-$', value='', regex=True, inplace=True)\n",
    "bpd.replace(r',', value='', regex=True, inplace=True)\n",
    "\n",
    "cols = bpd.columns.drop(['name', 'department_name', 'title', 'postal'])\n",
    "bpd[cols] = bpd[cols].apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv('./outputs/police_journal.csv', index_col='id')\n",
    "incidents = incidents[incidents.officer.notnull()]\n",
    "incidents = incidents[incidents.location.notnull()]\n",
    "incidents['badge'] = incidents.officer.str.split(pat = ' ').apply(lambda x: x[0])\n",
    "incidents['name'] = incidents.officer.str.split(pat = ' ').apply(lambda x: ' '.join(x[1:]))\n",
    "incidents.loc[:,'occ_time'] = incidents.occ_time.apply(pd.to_datetime)\n",
    "incidents.loc[:,'rep_time'] = incidents.rep_time.apply(pd.to_datetime)\n",
    "incidents = gpd.GeoDataFrame(incidents, geometry=gpd.points_from_xy(incidents.lng, incidents.lat))\n",
    "incidents.crs = 4326\n",
    "incidents = incidents.to_crs(epsg=2249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Boston Police districts\n",
    "districts_path = './data/districts.geojson'\n",
    "if path.exists(districts_path):\n",
    "    districts = gpd.read_file(districts_path).to_crs(epsg=2249)\n",
    "else:\n",
    "    districts = gpd.read_file('http://bostonopendata-boston.opendata.arcgis.com/datasets/9a3a8c427add450eaf45a470245680fc_5.geojson?outSR={%22latestWkid%22:2249,%22wkid%22:102686}', index_col='OBJECTID')\n",
    "    districts = districts.to_crs(epsg=2249)\n",
    "    districts = districts[['geometry', 'ID']].rename(columns={'ID': 'district'})\n",
    "    districts.to_crs(epsg=4326).to_file(districts_path, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read neighborhoods\n",
    "neighs_path = './data/neighs.geojson'\n",
    "if path.exists(neighs_path):\n",
    "    neighs = gpd.read_file(neighs_path).to_crs(epsg=2249)\n",
    "else:\n",
    "    neighs = gpd.read_file('http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson?outSR={%22latestWkid%22:2249,%22wkid%22:102686}')\n",
    "    neighs = neighs.to_crs(epsg=2249)\n",
    "    neighs = neighs[['geometry', 'Name']].rename(columns={'Name': 'neigh'})\n",
    "    neighs.to_crs(epsg=4326).to_file(neighs_path, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.sindex\n",
    "incidents = gpd.sjoin(incidents, districts, how='inner', op='within')\n",
    "incidents = incidents.drop('index_right', axis=1)\n",
    "incidents = gpd.sjoin(incidents, neighs, how='inner', op='within')\n",
    "incidents = incidents.drop('index_right', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericrobskyhuntley/Desktop/bpd/.venv/lib/python3.8/site-packages/d6tjoin/top1.py:118: UserWarning: Top1 join for name has duplicates\n",
      "  warnings.warn('Top1 join for %s has duplicates' %self.cfg_fuzzy_left_on)\n"
     ]
    }
   ],
   "source": [
    "fuzzy_merge = d6tjoin.top1.MergeTop1(incidents, bpd, fuzzy_left_on=['name'], fuzzy_right_on=['name'], top_limit=[3]).merge()\n",
    "incidents = fuzzy_merge['merged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.to_crs(epsg=4326).to_file('./outputs/incidents.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
